import os
import requests
import urllib.parse
import xml.etree.ElementTree as ET

import matplotlib.pyplot as plt
from wordcloud import WordCloud
import streamlit as st

# ====== ì„¤ì • ======
POTENS_API_URL = "https://ai.potens.ai/api/chat"
# ğŸ”¥ ë„¤ Potens API Key ì§ì ‘ ì…ë ¥ (ì›í•˜ë©´ ì—¬ê¸°ë§Œ ë°”ê¿”ë„ ë¨)
POTENS_API_KEY = "YRkzMbdIwkfjYFGKRGmkNOA83tEFzOzy"


# ====== Potens AI í˜¸ì¶œ (ê¸°ì—… ìš”ì•½) ======
def call_potens_ai(company_name: str) -> str:
    if not POTENS_API_KEY:
        return "âŒ POTENS_API_KEYê°€ ì½”ë“œì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."

    prompt = f"""
ë‹¹ì‹ ì€ ê¸°ì—… ë¶„ì„ì„ ë„ì™€ì£¼ëŠ” ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

ì•„ë˜ ê¸°ì—…ì— ëŒ€í•´ í•œêµ­ì–´ë¡œ ì´í•´í•˜ê¸° ì‰½ê²Œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.

[ê¸°ì—…ëª…]
{company_name}

[ìš”ì²­ì‚¬í•­]
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±
- ë„ˆë¬´ ì¥í™©í•˜ì§€ ì•Šê²Œ, í•µì‹¬ ìœ„ì£¼ë¡œ ì •ë¦¬

[ì¶œë ¥ í•­ëª©]
1. í•œ ì¤„ ìš”ì•½
2. íšŒì‚¬ ê°œìš” (ì„¤ë¦½ì—°ë„, ì—…ì¢…, ì£¼ìš” ì‚¬ì—… ë“±)
3. í•µì‹¬ ì‚¬ì—…/ì„œë¹„ìŠ¤
4. íˆ¬ì/ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œì˜ ê°•ì 
5. ë¦¬ìŠ¤í¬ ìš”ì¸
6. ìµœê·¼ ì£¼ìš” ì´ìŠˆ (ì•Œê³  ìˆëŠ” ë²”ìœ„ ë‚´ì—ì„œ bullet list)
""".strip()

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {POTENS_API_KEY}",
    }
    data = {"prompt": prompt}

    try:
        resp = requests.post(POTENS_API_URL, headers=headers, json=data, timeout=60)
        resp.raise_for_status()
        body = resp.json()
        return body.get("message", "AI ì‘ë‹µì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        return f"âŒ Potens API í˜¸ì¶œ ì˜¤ë¥˜: {e}"


# ====== Google News RSSì—ì„œ ìµœì‹  ê¸°ì‚¬ 20ê°œ ======
def fetch_google_news(company_name: str, max_results: int = 20):
    encoded_query = urllib.parse.quote(company_name)
    url = (
        f"https://news.google.com/rss/search?q={encoded_query}"
        "&hl=ko&gl=KR&ceid=KR:ko"
    )

    try:
        resp = requests.get(url, timeout=20)
        resp.raise_for_status()
    except Exception as e:
        return [], f"ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    try:
        root = ET.fromstring(resp.content)
        items = root.findall(".//item")
        articles = []
        for item in items[:max_results]:
            raw_title = (item.findtext("title") or "").strip()
            link = (item.findtext("link") or "").strip()
            pub_date = (item.findtext("pubDate") or "").strip()
            description = (item.findtext("description") or "").strip()

            # ì œëª©ì—ì„œ ì¶œì²˜ ë¶„ë¦¬: "ì œëª© - ë§¤ì²´ëª…"
            source = ""
            title = raw_title
            if " - " in raw_title:
                title, source = raw_title.rsplit(" - ", 1)
                title = title.strip()
                source = source.strip()

            # description ì•ˆì˜ hrefì—ì„œ ì‹¤ì œ ê¸°ì‚¬ ë§í¬ ì¶”ì¶œ ì‹œë„
            real_link = link
            if 'href="' in description:
                start = description.find('href="') + len('href="')
                end = description.find('"', start)
                if start > -1 and end > -1:
                    real_link = description[start:end]

            articles.append(
                {
                    "title": title or raw_title,
                    "source": source,
                    "link": real_link,
                    "pub_date": pub_date,
                }
            )
        return articles, ""
    except Exception as e:
        return [], f"ë‰´ìŠ¤ RSS íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"


# ====== ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ======
def create_wordcloud_from_articles(articles):
    text_parts = [a.get("title", "") for a in articles]
    text = " ".join(text_parts)

    if not text.strip():
        return None, "ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."

    # í•œê¸€ í°íŠ¸ ê²½ë¡œ (WSL/ë¦¬ëˆ…ìŠ¤/ìœˆë„ìš° ê³ ë ¤)
    font_path = None
    candidate_paths = [
        "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
        "/usr/share/fonts/truetype/nanum/NanumSquareNeo-bRg.ttf",
        "/mnt/c/Windows/Fonts/malgun.ttf",  # WSLì—ì„œ ìœˆë„ìš° í•œê¸€ í°íŠ¸
        "/mnt/c/Windows/Fonts/NGULIM.TTF",
    ]
    for path in candidate_paths:
        if os.path.exists(path):
            font_path = path
            break

    try:
        wc = WordCloud(
            width=800,
            height=400,
            background_color="white",
            font_path=font_path,
        ).generate(text)

        fig, ax = plt.subplots(figsize=(10, 5))
        ax.imshow(wc, interpolation="bilinear")
        ax.axis("off")
        plt.tight_layout()
        return fig, ""
    except Exception as e:
        return None, f"ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"


# ====== ìŠ¤íƒ€ì¼ (í† ìŠ¤ ëŠë‚Œ + í° ì„¹ì…˜ ì œëª© + ì˜ˆìœ ê²€ìƒ‰ì°½) ======
def inject_toss_style():
    st.markdown(
        """
        <style>
        .stApp {
            background: #f4f6fa;
            font-family: -apple-system, BlinkMacSystemFont, "SF Pro Text", system-ui, sans-serif;
        }

        .main-title {
            padding-top: 1.5rem;
            padding-bottom: 0.5rem;
        }

        .pill {
            display: inline-block;
            padding: 0.15rem 0.6rem;
            border-radius: 999px;
            font-size: 0.75rem;
            font-weight: 500;
            background: #eff4ff;
            color: #3b82f6;
            margin-top: 0.1rem;
        }

        h1 {
            font-size: 2.2rem;
            font-weight: 700;
        }

        h2 {
            font-size: 1.6rem;
            font-weight: 700;
        }

        /* ê²€ìƒ‰ ì˜ì—­ */
        .search-wrapper {
            margin-top: 1.6rem;
            margin-bottom: 1.2rem;
        }

        .search-label {
            font-size: 0.95rem;
            font-weight: 600;
            color: #4b5563;
            margin-bottom: 0.25rem;
        }

        input[type="text"] {
            border-radius: 999px !important;
            border: 1px solid #d1d5db !important;
            padding: 0.55rem 1rem !important;
            background: #ffffff !important;
            font-size: 0.95rem !important;
            box-shadow: 0 4px 10px rgba(15, 23, 42, 0.05);
        }

        .stButton button {
            background: #3182f6;
            color: white;
            border-radius: 999px;
            padding: 0.55rem 1.4rem;
            border: none;
            font-weight: 600;
            font-size: 0.95rem;
            box-shadow: 0 6px 18px rgba(37, 99, 235, 0.35);
        }
        .stButton button:hover {
            background: #2563eb;
        }

        /* ì„¹ì…˜ ëŒ€ì œëª© pill */
        .section-title {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            background: #ffffff;
            padding: 0.55rem 1.3rem;
            border-radius: 999px;
            box-shadow: 0 4px 18px rgba(15, 23, 42, 0.10);
            border: 1px solid #e5e7eb;
            margin-top: 2.0rem;
            margin-bottom: 0.6rem;
        }
        .section-title-icon {
            font-size: 1.35rem;
        }
        .section-title-text {
            font-size: 1.45rem;
            font-weight: 700;
        }

        hr {
            margin: 0.7rem 0 0.5rem 0;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )


# ====== ë©”ì¸ ì•± ======
def main():
    st.set_page_config(page_title="AI ê¸°ì—…ë¶„ì„", layout="wide")
    inject_toss_style()

    # ìƒë‹¨ íƒ€ì´í‹€
    st.markdown(
        """
        <div class="main-title">
            <h1>AI ê¸°ì—…ë¶„ì„</h1>
            <span class="pill">ë² íƒ€ Â· Potens AI ê¸°ë°˜</span>
            <p style="color:#6b7280; margin-top:0.6rem; font-size:0.9rem;">
                ì•Œê³  ì‹¶ì€ íšŒì‚¬ë¥¼ ê²€ìƒ‰í•˜ë©´, AIê°€ ê¸°ì—… ê°œìš”ë¥¼ ì •ë¦¬í•˜ê³  êµ¬ê¸€ ë‰´ìŠ¤ì—ì„œ ìµœì‹  ì´ìŠˆë¥¼ ëª¨ì•„ë“œë¦½ë‹ˆë‹¤.
            </p>
        </div>
        """,
        unsafe_allow_html=True,
    )

    # ---- ê²€ìƒ‰ ì˜ì—­ (ì˜ˆìœ ê²€ìƒ‰ì°½ + ì•„ë˜ ë²„íŠ¼) ----
    st.markdown('<div class="search-wrapper">', unsafe_allow_html=True)
    st.markdown('<div class="search-label">ê¸°ì—…ëª… ê²€ìƒ‰</div>', unsafe_allow_html=True)
    st.caption("ë¶„ì„í•˜ê³  ì‹¶ì€ ê¸°ì—…ëª…ì„ ì…ë ¥í•˜ê³  ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ë³´ì„¸ìš”.")

    company_query = st.text_input(
        label="ê¸°ì—…ëª… ì…ë ¥",
        placeholder="ì˜ˆ: ì‚¼ì„±ì „ì, ì¹´ì¹´ì˜¤, ë„¤ì´ë²„, í•˜ë‚˜ì €ì¶•ì€í–‰ ë“±",
        label_visibility="collapsed",
    )

    # ë²„íŠ¼: ê°€ìš´ë° ì •ë ¬ ëŠë‚Œ
    btn_col1, btn_col2, btn_col3 = st.columns([2, 1, 2])
    with btn_col2:
        search_clicked = st.button("ê¸°ì—… ë¶„ì„í•˜ê¸°", use_container_width=True)

    st.markdown("</div>", unsafe_allow_html=True)

    if not search_clicked:
        return

    company = company_query.strip()
    if not company:
        st.warning("ë¨¼ì € ê¸°ì—…ëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        return

    # 1) ê¸°ì—… ìš”ì•½
    with st.spinner(f"AIê°€ '{company}' ê¸°ì—…ì„ ë¶„ì„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        summary_md = call_potens_ai(company)

    # 2) ë‰´ìŠ¤
    with st.spinner(f"'{company}' ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        articles, news_err = fetch_google_news(company)

    # ---- ê¸°ì—… ìš”ì•½ ì„¹ì…˜ ----
    left_col, right_col = st.columns([1.2, 1])

    with left_col:
        st.markdown(
            """
            <div class="section-title">
                <span class="section-title-icon">ğŸ“Œ</span>
                <span class="section-title-text">ê¸°ì—… ìš”ì•½</span>
            </div>
            """,
            unsafe_allow_html=True,
        )
        st.caption("AIê°€ ê³µê°œëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ë¦¬í•œ ë‚´ìš©ì…ë‹ˆë‹¤.")
        st.markdown("---")
        st.markdown(summary_md)

    # ---- ìµœì‹  ë‰´ìŠ¤ ì„¹ì…˜ ----
    with right_col:
        st.markdown(
            """
            <div class="section-title">
                <span class="section-title-icon">ğŸ“°</span>
                <span class="section-title-text">ìµœì‹  ë‰´ìŠ¤ (Google News)</span>
            </div>
            """,
            unsafe_allow_html=True,
        )
        st.caption("ìµœì‹ ìˆœìœ¼ë¡œ ìµœëŒ€ 20ê°œ ë‰´ìŠ¤ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        st.markdown("---")

        if news_err:
            st.error(news_err)
        elif not articles:
            st.info("í‘œì‹œí•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for a in articles:
                title = a["title"] or "ì œëª© ì—†ìŒ"
                link = a["link"]
                pub_date = a["pub_date"]
                source = a["source"]

                if link:
                    st.markdown(f"- [{title}]({link})")
                else:
                    st.markdown(f"- {title}")

                meta_parts = []
                if pub_date:
                    meta_parts.append(pub_date)
                if source:
                    meta_parts.append(source)
                if meta_parts:
                    st.caption(" Â· ".join(meta_parts))

    # ---- ì›Œë“œí´ë¼ìš°ë“œ ì„¹ì…˜ ----
    st.markdown(
        """
        <div class="section-title">
            <span class="section-title-icon">â˜</span>
            <span class="section-title-text">ë‰´ìŠ¤ í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ</span>
        </div>
        """,
        unsafe_allow_html=True,
    )
    st.caption("ìœ„ 20ê°œ ë‰´ìŠ¤ì˜ ì œëª©ì„ ê¸°ë°˜ìœ¼ë¡œ í‚¤ì›Œë“œë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.")
    st.markdown("---")

    if articles:
        fig, wc_err = create_wordcloud_from_articles(articles)
        if wc_err:
            st.error(wc_err)
        elif fig is None:
            st.info("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        else:
            st.pyplot(fig)
    else:
        st.info("ë¨¼ì € ë‰´ìŠ¤ê°€ ì¡°íšŒë˜ì–´ì•¼ ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
